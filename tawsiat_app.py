
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© - Ù†Ø¸Ø§Ù… ØªÙˆØµÙŠØ§Øª Ù…Ù‚Ø³Ù… Ø§Ø³ØªØ«Ù…Ø§Ø± / Ù…Ø¶Ø§Ø±Ø¨Ø© - Streamlit
# ØªÙ…Ù‡ÙŠØ¯ Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª ÙˆØ§Ù„Ø±Ø¨Ø· Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Polygon + NewsAPI + Google RSS

import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

st.set_page_config(page_title="ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø´Ø±Ø¹ÙŠØ©", layout="wide")
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø´Ø±Ø¹ÙŠ - ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©")

API_KEY = "YOUR_API_KEY_HERE"  # Polygon
NEWS_API_KEY = "9071a77124c3425ab844422c724a93b5"  # NewsAPI

stocks = {
    "Ø§Ø³ØªØ«Ù…Ø§Ø±": ["AAPL", "NVDA", "LLY", "V", "MA"],
    "Ù…Ø¶Ø§Ø±Ø¨Ø©": ["ORCL", "AI"]
}

def fetch_data(ticker):
    end = datetime.now().date()
    start = end - timedelta(days=180)
    url = f"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/{start}/{end}?adjusted=true&sort=asc&limit=120&apiKey={API_KEY}"
    r = requests.get(url)
    if r.status_code != 200:
        return pd.DataFrame()
    data = r.json().get("results", [])
    if not data:
        return pd.DataFrame()
    df = pd.DataFrame(data)
    df['t'] = pd.to_datetime(df['t'], unit='ms')
    df.set_index('t', inplace=True)
    df.rename(columns={'c': 'Close', 'v': 'Volume'}, inplace=True)
    return df

def fetch_news(ticker):
    results = []

    # NewsAPI
    url_api = f"https://newsapi.org/v2/everything?q={ticker}&sortBy=publishedAt&pageSize=1&apiKey={NEWS_API_KEY}"
    r1 = requests.get(url_api)
    if r1.status_code == 200:
        articles = r1.json().get("articles", [])
        if articles:
            article = articles[0]
            title = article['title']
            url = article['url']
            desc = article['description'] or ""
            sentiment = "ğŸ”´ Ø³Ù„Ø¨ÙŠ" if any(word in desc.lower() for word in ["downgrade", "lawsuit", "loss", "decline", "drop", "cut"]) else "ğŸŸ¢ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
            results.append((title, url, sentiment))

    # Google News RSS
    from xml.etree import ElementTree as ET
    rss_url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
    r2 = requests.get(rss_url)
    if r2.status_code == 200:
        root = ET.fromstring(r2.content)
        items = root.findall(".//item")
        if items:
            title = items[0].find("title").text
            url = items[0].find("link").text
            desc = items[0].find("description").text if items[0].find("description") is not None else ""
            sentiment = "ğŸ”´ Ø³Ù„Ø¨ÙŠ" if any(word in desc.lower() for word in ["downgrade", "lawsuit", "loss", "decline", "drop", "cut"]) else "ğŸŸ¢ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
            results.append((title, url, sentiment))

    return results

def analyze_stock(df, mode):
    df['EMA'] = df['Close'].ewm(span=50 if mode=="Ø§Ø³ØªØ«Ù…Ø§Ø±" else 9).mean()
    close = df['Close'].iloc[-1]
    ema = df['EMA'].iloc[-1]
    signal = close > ema if mode=="Ù…Ø¶Ø§Ø±Ø¨Ø©" else close < ema
    stop = round(close * (0.95 if mode=="Ø§Ø³ØªØ«Ù…Ø§Ø±" else 0.97), 2)
    targets = [round(close * r, 2) for r in [1.03, 1.06, 1.10]]
    duration = "Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ† - Ø´Ù‡Ø±" if mode == "Ø§Ø³ØªØ«Ù…Ø§Ø±" else "1-3 Ø£ÙŠØ§Ù…"
    reason = "ÙƒØ³Ø± Ù…ØªÙˆØ³Ø· EMA" if signal else "Ø¯ÙˆÙ† Ù…ØªÙˆØ³Ø· EMA Ø¨Ø¯ÙˆÙ† Ø§Ø®ØªØ±Ø§Ù‚"
    confidence = 0
    if signal:
        confidence += 50
        if mode == "Ø§Ø³ØªØ«Ù…Ø§Ø±" and close < ema * 0.98:
            confidence += 25
        if mode == "Ù…Ø¶Ø§Ø±Ø¨Ø©" and df['Volume'].iloc[-1] > df['Volume'].rolling(20).mean().iloc[-1]:
            confidence += 25
    return signal, targets, stop, duration, reason, confidence, df.index[-1].date()

for mode in ["Ø§Ø³ØªØ«Ù…Ø§Ø±", "Ù…Ø¶Ø§Ø±Ø¨Ø©"]:
    st.header(f"{'ğŸ‘‘' if mode=='Ø§Ø³ØªØ«Ù…Ø§Ø±' else 'âš¡'} Ø£Ø³Ù‡Ù… {mode}")
    valid_signals = []
    invalid_signals = []
    for symbol in stocks[mode]:
        df = fetch_data(symbol)
        if df.empty:
            invalid_signals.append((symbol, None, None))
            continue
        signal, targets, stop, dur, reason, confidence, last_date = analyze_stock(df, mode)
        news_items = fetch_news(symbol)
        if signal:
            valid_signals.append((symbol, df, targets, stop, dur, reason, confidence, last_date, news_items))
        else:
            invalid_signals.append((symbol, df, last_date, news_items))

    if valid_signals:
        st.subheader("âœ… Ø£Ø³Ù‡Ù… ØµØ§Ù„Ø­Ø© Ù„Ù„Ø¯Ø®ÙˆÙ„")
        cols = st.columns(len(valid_signals))
        for i, (symbol, df, targets, stop, dur, reason, confidence, last_date, news_items) in enumerate(valid_signals):
            with cols[i]:
                st.markdown(f"### {symbol}")
                st.metric(label="ğŸ“ˆ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ", value=f"${df['Close'].iloc[-1]:.2f}")
                st.markdown(f"**ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {last_date}")
                st.markdown(f"**ğŸ§­ Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ©:** {mode}")
                st.markdown(f"**âœ… Ø¥Ø´Ø§Ø±Ø© Ø¯Ø®ÙˆÙ„:** Ù†Ø¹Ù…")
                st.markdown(f"ğŸ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù:")
                for idx, t in enumerate(targets, 1):
                    st.markdown(f"- ğŸ¯ Ù‡Ø¯Ù {idx}: {t}")
                st.markdown(f"ğŸ›‘ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {stop}")
                st.markdown(f"â± Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: {dur}")
                st.markdown(f"ğŸ§  Ø§Ù„Ø³Ø¨Ø¨: {reason}")
                st.markdown(f"ğŸ’¡ Ù…Ø¤Ø´Ø± Ø§Ù„Ø«Ù‚Ø©: `{confidence}%`")
                if news_items:
                    for title, url, sentiment in news_items:
                        st.markdown(f"**ğŸ“¢ Ø®Ø¨Ø±:** [{title}]({url}) â€“ {sentiment}")

    if invalid_signals:
        st.subheader("ğŸš« Ø£Ø³Ù‡Ù… ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø¯Ø®ÙˆÙ„")
        cols = st.columns(len(invalid_signals))
        for i, (symbol, df, last_date, news_items) in enumerate(invalid_signals):
            with cols[i]:
                st.markdown(f"### {symbol}")
                if df is None:
                    st.error(f"âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ù€ {symbol}")
                else:
                    st.metric(label="ğŸ“ˆ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ", value=f"${df['Close'].iloc[-1]:.2f}")
                    st.markdown(f"**ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {last_date}")
                    st.markdown(f"**ğŸ§­ Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ©:** {mode}")
                    st.markdown("**âœ… Ø¥Ø´Ø§Ø±Ø© Ø¯Ø®ÙˆÙ„:** Ù„Ø§")
                    if news_items:
                        for title, url, sentiment in news_items:
                            st.markdown(f"**ğŸ“¢ Ø®Ø¨Ø±:** [{title}]({url}) â€“ {sentiment}")
